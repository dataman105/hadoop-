1 centos 7的安装
1.1 下载centos 7.iso进行虚拟机安装
1.2 配置网络，在主机上win+r查看DNS
1.3 虚拟机选择桥接模式
1.4 配置网络，/etc/sysconfig/network-scripts/ifcfg-ens33中添加DNS1=1.2中的DNS，并设置ONBOOT=yes
1.5 保存，重启电脑


2 hadoop的安装和配置

2.1 hadoop的基础环境配置
2.1.1 创建一个主机，hostname hadoop
2.1.2 文件中修改主机名，/etc/sysconfig/network,HOSTNAME=hadoop,保存
2.1.3 映射关系，/etc/hosts,192.168.2.114 hadoop
2.1.4 重启，reboot

2.2 ssh配置
2.2.1 ssh 192.168.2.114 连接
2.2.2 配置免密码登陆
2.2.3 生成秘钥，ssh-keygen -t rsa 四个回车
2.2.4 复制秘钥到本机，ssh-copy-id 192.168.2.114
完成ssh的免密连接

2.3 JDK的安装和环境配置
2.3.1 创建文件夹，tools(工具文件夹),software（软件安装目录）,data(数据)
2.3.2 安装rz的包，可直接上传文件，yum install -y lrzsz
2.3.3 下载JDK 7U67 linux版本，rz导入到tools
2.3.4 解压 tar -zxvf jdk-8u191-linux-x64.tar.gz -C ../software
2.3.5 mkdir jdk, mv jdk1.7/* jdk
2.3.6 配置JAVA环境
      vi /etc/profile
      export JAVA_HOME=/home/software/jdk
      export PATH=$PATH:$JAVA_HOME/bin
      保存
      刷新：source /etc/profile


2.4 添加用户
2.4.1 添加用户 adduser hadoop01
2.4.2 设置密码 passwd hadoop01
2.4.3 切换用户 su hadoop01
2.4.4 查看当前用户 whoami
2.4.5 赋权
2.4.6 chmod u+x /etc/sudoers
2.4.7 编辑vi /etc/sudoers,加入hadoop01权限


2.5 安装hadoop
2.5.1 http://hadoop.apache.org/docs
2.5.2 查看单节点安装
2.5.3 下载hadoop 3.1
2.5.4 测试 bin/hadoop

2.6 配置hadoop
2.6.1 core-site.xml配置
    <property>
       <name>fs.defaultFS</name>
       <value>hdfs://192.168.2.114</value>
    </property>
    <property>
       <name>hadoop.tmp.dir</name>
       <value>/home/software/hadoop-3.1.1/data/tmp</value>
  #在hadoop目录下创建data/tmp文件路径
    </property>

2.6.2 hdfs-site.xml配置
	<property>
		<name>dfs.replication</name>
		<value>1</value>
	</property>

2.6.3 hadoop-env.sh
	export JAVA_HOME=/home/software/jdk
	export TANODE_USER=root
	export HDFS_DATANODE_SECURE_USER=hdfs
	export HDFS_NAMENODE_USER=root
	export HDFS_SECONDARYNAMENODE_USER=root
	export YARN_RESOURCEMANAGER_USER=root
	export HADOOP_SECURE_DN_USER=yarn
	export YARN_NODEMANAGER_USER=root
  
格式化：bin/hadoop namenode -format
启动:sbin/start-all.sh

2.7 yarn配置
2.7.1 mapred-site.xml配置
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>

2.7.2 yarn-site.xml配置
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>

启动：sbin/start-yarn.sh

检查启动项：jps
#一定要保证datanode节点打开，如果没有打开报错，需要删除data/tmp目录下的文件，重启格式化，重启

2.8上传文件到hdfs
bin/hadoop fs -put /home/data/wordtest /    #/home/data/wordtest是本地文件  /是hdfs文件


2.9 计算词频
2.9.1 mapred-site.xml配置
	<property>
	  <name>yarn.app.mapreduce.am.env</name>
	  <value>HADOOP_MAPRED_HOME=${HADOOP_HOME}</value>
	</property>
	<property>
	  <name>mapreduce.map.env</name>
	  <value>HADOOP_MAPRED_HOME=${HADOOP_HOME}</value>
	</property>
	<property>
	  <name>mapreduce.reduce.env</name>
	  <value>HADOOP_MAPRED_HOME=${HADOOP_HOME}</value>
	</property>

执行：bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar  wordcount /wordtest /out

#查看hdfs文件目录：bin/hadoop fs -ls /





















